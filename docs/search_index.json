[["index.html", "Data Management for Clinical Researchers Preface", " Data Management for Clinical Researchers Albert Cobos Preface This is an introductory book on data management for clinical researchers. The ability to manage data is a fundamental skill for data analysts, because only rarely the initial state of a dataset is adequate to perform the desired analysis. Rather, preparation tasks are usually needed to transform the data so that analysis functions can be used. In fact, these tasks tend to be more complex, more prone to errors, and much more time consuming, than the analysis itself. All data management tasks can be accomplished using base R. However, several R packages make them easier. Among these, packages dplyr, tidyr, stingr and forcats will be used in this book. These (and other) packages form a collection known as the tidyverse, which is integrated in a package of the same name (tidyverse). Once installed, you can load it with: library(tidyverse) And that’s all you need to start! "],["working-with-dataframes.html", "1 Working with dataframes 1.1 Subsetting dataframes 1.2 Reshaping dataframes 1.3 Summarising rows of a dataframe 1.4 Combining dataframes Resources Exercises", " 1 Working with dataframes Dataframes are the most common object used to store data in R, and many data analysis functions expect a dataframe as input. Frequently however, dataframes will need to undergo certain transformations, so that they satisfy the structure required by analysis functions. These transformations may involve subsetting rows or columns, aggregating rows, reshaping or combining dataframes. Although base R includes operators and functions allowing to perfom these and other dataframe operations, packages dplyr and tidyr make them easier hand have some additional advantages, such as allowing to chain operations with the pipe operator (%&gt;%). In this chapter, we will see how to perform all the above mentioned transformations in turn, using functions from the dplyr and tidyr packages. However, because these two packages are part of the tidyverse, you do not need to load them (provided you have loaded tidyverse!). library(tidyverse) For illustrative purposes, we will use data from a random sample of 500 patients participating in the DISEHTAE study on the diagnosis, follow-up and control of arterial hypertensin in Spain. This was a cross-sectional nationwide study, with external auditing performed in 7802 hypertensive subjects who had attended one of 107 primary care centers from 14 regions in Spain during 2003. Among other variables, blood pressure (BP) measurements documented in each patient’s clinical record were collected for a maximum of six follow-up visits in a natural year. Table 1.1 lists the variables contained in the data file. Download the DISETHAE data Table 1.1: Variables in the dataset variable description coding pid patient identification number data_xtract_dt data extraction date dd/mm/yyyy region region in Spain 1=Andalucía, 2=Aragón, 3=Asturias, 4=Baleares, 5=Canarias, 6=Cantabria, 7=Castilla-La Mancha, 8=Castilla-León, 9=Catalunya, 10=Extremadura, 11=Galicia, 12=La Rioja, 13=Madrid, 14=Murcia, 15=Navarra, 16=País Vasco, 17=Valencia age age (years) at study start date (01.Jan.2003) sex patient’s sex 1=male, 2=female ah_dx_dt date of diagnosis of arterial hypertension dd/mm/yyyy sbp_v1 systolic blood pressure, visit 1 (mmHg) dbp_v1 diastolic blood pressure, visit 1 (mmHg) sbp_v2 same, visit 2 dbp_v2 same, visit 2 sbp_v3 same, visit 3 dbp_v3 same, visit 3 sbp_v4 same, visit 4 dbp_v4 same, visit 4 sbp_v5 same, visit 5 dbp_v5 same, visit 5 sbp_v6 same, visit 6 dbp_v6 same, visit 6 glucose blood glucose concentraton (mg/dl) dx_dm diagnosed with diabetes mellitus 1=yes, 2=no total_c total cholesterol (mg/dl) hdl_c HDL-choleterol (mg/dl) ldl_c LDL-choleterol (mg/dl) trigly triglycerides (mg/dl) dx_dyslip diagnosed with dyslipidemia 1=yes, 2=no smoke smoking status 1=current smoker, 2=never smoker, 3=ex-smoker, 4=unknown weight body weight (kg) height body height (meters) dx_lvh diagnosed with left ventricula hypertrophy 1=yes, 2=no cv_risk_record cardiovascular risk assessment recorded 1=yes, 2=no, 3=not applicable (previous cardiovascular event) creatinine creatinine concentration in blood (mg/dl) lmr lifestyle modification recommendation 1=yes, 2=no bb treated with beta-blockers 1=yes, 2=no diur treated with diuretics 1=yes, 2=no acei treated with angiotensin converting enzyme inhibitors 1=yes, 2=no arb treated with angiotensin receptor blockers 1=yes, 2=no cbb treated with calcium channel blockers 1=yes, 2=no ab treated with alpha_blockers 1=yes, 2=no other treated with other antihypertensive drugs 1=yes, 2=no The following script reads the data with function import() from package rio. The argument which specifies the spreadsheet to be read (data), since the MS Excel file has more than one spreadsheet. The resulting dataframe is saved as ah: ah &lt;- rio::import(&quot;./data/hta.xlsx&quot;, which = &quot;data&quot;) 1.1 Subsetting dataframes Subsetting dataframes is a very common task. When a dataframe has many variables (columns), we may want to subset the variables needed for an analysis as outlined in table 1.2. In other instances we may want to restrict our analysis to a particular subset of observations (rows), as depicted in table 1.3. Table 1.2: Subset variables (columns) x1 x2 x3 x4 x5 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4 x2 x3 x5 1 1 1 2 2 2 3 3 3 4 4 4 Table 1.3: Subset observations (rows) x1 x2 x3 x4 x5 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4 x1 x2 x3 x4 x5 2 2 2 2 2 3 3 3 3 3 1.1.1 Subsetting variables (columns) The select() function in dplyr allows to select variables from a dataframe. The first argument to this function must be the dataframe we want to subset. After it, we may simply name the variables we want to retain. In the example below we chain the head() function with the pipe operator %&gt;% to limit the output to the first 6 rows: select(ah, pid, region, age, sex) %&gt;% head() pid region age sex 1 11 6 52 1 2 15 6 57 2 3 20 1 62 1 4 24 10 69 2 5 33 10 70 2 6 37 9 64 2 The variables to select may be specified one by one, comma separated, as in the above example. A range of consecutive variables can be indicated using the colon (:). Also, we can use the minus sign - to indicate variables to exclude: select(ah, pid, pid:sex, -data_xtract_dt) %&gt;% head() pid region age sex 1 11 6 52 1 2 15 6 57 2 3 20 1 62 1 4 24 10 69 2 5 33 10 70 2 6 37 9 64 2 Some helper functions are available to facilitate the subsetting based on the variable names, which is very handy if variables are named in a consistent way. In dataframe ah, all date variables are suffixed with the string “dt”. Similarly, the name of all diagnostic variables is prefixed with “dx”. Suppose we want to select all variables containing the string “dx”. This can be easily done with the helper function contains(): select(ah, contains(&quot;dx&quot;)) %&gt;% # all variables containing &quot;dx&quot; head() ah_dx_dt dx_dm dx_dyslip dx_lvh 1 1998-01-01 2 2 2 2 1997-01-01 2 2 2 3 2003-04-10 2 2 2 4 1993-01-01 2 1 2 5 1994-01-01 2 1 2 6 1995-04-07 1 2 2 Helper functions starts_with() and ends_with() allow to select variables preffixed or suffixed with the specified string. These are useful to select all diagnostic or all date variables, respectively: select(ah, starts_with(&quot;dx&quot;)) %&gt;% # all diagnostic vars head() dx_dm dx_dyslip dx_lvh 1 2 2 2 2 2 2 2 3 2 2 2 4 2 1 2 5 2 1 2 6 1 2 2 select(ah, ends_with(&quot;dt&quot;)) %&gt;% # all dates head() data_xtract_dt ah_dx_dt 1 2003-03-15 1998-01-01 2 2003-03-15 1997-01-01 3 2003-05-13 2003-04-10 4 2003-05-27 1993-01-01 5 2003-05-28 1994-01-01 6 2003-06-14 1995-04-07 When some variables are measured more than once, it is common to number repetitions by suffixing a repetion number, as is the case of blood pressure measurements (sbp_v1 to sbp_v6 and dbp_v1 to dbp_v6). The helper function num_range() allows to select variables so named, by indicating the constant part of the variable names as the first argument, and the numeric range of repetitions to select as the second argument: select(ah, num_range(&quot;sbp_v&quot;, 1:3)) %&gt;% # SBP repetitions 1 to 3 head() sbp_v1 sbp_v2 sbp_v3 1 130 140 NA 2 130 120 120 3 130 120 140 4 150 160 140 5 140 145 140 6 159 160 159 select(ah, num_range(&quot;dbp_v&quot;, 2:5)) %&gt;% # DBP repetitions 2 to 5 head() dbp_v2 dbp_v3 dbp_v4 dbp_v5 1 80 NA NA NA 2 80 90 90 NA 3 80 80 80 80 4 85 95 85 90 5 85 80 85 80 6 80 75 80 79 If the names of the variables to be selected are contained in a character vector, the helper function one_of() is handy: demovars &lt;- c(&quot;pid&quot;, &quot;age&quot;, &quot;sex&quot;, &quot;region&quot;) demo &lt;- select(ah, one_of(demovars)) head(demo) pid age sex region 1 11 52 1 6 2 15 57 2 6 3 20 62 1 1 4 24 69 2 10 5 33 70 2 10 6 37 64 2 9 1.1.2 Subsetting observations (rows) The rows of a dataframe can be subsetted in several ways: by position (i.e., row number), at random, or according to some logical condition. When working with dataframes having a very large number of observations, it is convenient to use a smaller subset to start programming the analysis, so that the execution doesn’t take too long. Only when we have verified that the R code works well, we will run it on the whole dataframe. To this end, the slice() function is useful to select a range of rows: slice(demo, 1:3) # rows 1 to 3 pid age sex region 1 11 52 1 6 2 15 57 2 6 3 20 62 1 1 Functions slice_min() and slice_max() allow the selection of observartions having the highest or lowest values in a variable: slice_min(demo, age, n=3) # the 3 youngest cases pid age sex region 1 1308 32 1 7 2 398 33 1 5 3 1420 34 2 5 slice_max(demo, age, n=5) # the 5 oldest cases pid age sex region 1 562 99 2 3 2 3551 91 2 17 3 1311 89 2 13 4 981 88 2 5 5 1847 87 1 9 6 3355 87 2 1 7 5080 87 2 17 If we want to take a random sample of observations, sample_n() allows to specify the size of the sample we want to draw from the dataframe. When using this (or any other function using the random number generator), we need to set the seed if we want the result of the function to be reproducible (i.e, to give the same result every time we execute the code). This will select five cases at random from dataframe demo: set.seed(1) # for reproducibility sample_n(demo, size = 5) # actual sampling of 5 cases from demo pid age sex region 1 5248 61 2 6 2 2305 80 1 9 3 1590 73 2 9 4 6778 62 1 14 5 7429 59 2 9 Last, observations may be selected based on a logical condition, that is, something that resolves to a logical value (TRUE or FALSE) for each row. Conditions are specified by means of relational operators (&gt;, &gt;=, &lt;, &lt;=, ==, and !=), and may be combined with logical operators (&amp;, |, !). The following example retains all females aged more than 65 (but then we use head() to limit the length of the output): filter(demo, sex == 2 &amp; age &gt; 65) %&gt;% head() pid age sex region 1 24 69 2 10 2 33 70 2 10 3 114 73 2 5 4 155 66 2 5 5 169 72 2 5 6 193 78 2 5 The helper function between()is useful to specify ranges for numeric variables: filter(demo, sex == 2 &amp; between(age, 40, 65)) %&gt;% head() pid age sex region 1 15 57 2 6 2 37 64 2 9 3 50 55 2 2 4 176 60 2 5 5 177 54 2 5 6 224 62 2 5 Also, functions resolving to a logical value can be used, for instance to select cases with missing values (here we do not use head() to limit the output, because the number of rows filtered in limited) … filter(demo, is.na(sex)) pid age sex region 1 397 42 NA 5 2 2651 52 NA 9 3 3779 46 NA 13 4 4221 77 NA 17 5 4650 70 NA 2 6 5087 71 NA 17 7 6195 44 NA 8 8 6232 38 NA 14 9 7154 65 NA 1 … or not being missing : filter(demo, !is.na(sex)) %&gt;% head() pid age sex region 1 11 52 1 6 2 15 57 2 6 3 20 62 1 1 4 24 69 2 10 5 33 70 2 10 6 37 64 2 9 1.2 Reshaping dataframes Given a set of data, there are always several possible ways to arrange them in a dataframe. Figure 1.4 illustrates two different ways of arranging three variables (var_1, var_2 and var_3) evaluated in three individuals (id). On the left arrangement, sometines called wide format, each individual is a row and each variable is a column of the dataframe. On the right arrangement (called long format), each individual takes one row per variable and therefore three rows overall. Table 1.4: Two ways to structure the same data wide format id var_1 var_2 var_3 1 a b c 2 d e f 3 g h i long format id variable value 1 var_1 a 1 var_2 b 1 var_3 c 2 var_1 d 2 var_2 e 2 var_3 f 3 var_1 g 3 var_2 h 3 var_3 i Each of these arrangements has its own advantages and shortcomings, and we will choose one or the other as convenient. For instance, the wide format may be required by some analysis functions, while a graphic function may require the long format. Therefore, it is crucial to know how to reshape the data in a dataframe. The tidyr package has a couple of functions to reshape dataframes: pivot_long(): to convert a (wide) dataframe to long format pivot_wide(): tp convert a (long) dataframe to wide format To illustrate the use of these two functions, we select the patient identifier (pid) and all blood pressure measurements from dataframe ah, we save the resulting dataframe as bp, and we show its first six rows: bp_wide &lt;- select(ah, pid, contains(&quot;bp&quot;)) head(bp_wide) pid sbp_v1 dbp_v1 sbp_v2 dbp_v2 sbp_v3 dbp_v3 sbp_v4 dbp_v4 sbp_v5 dbp_v5 1 11 130 80 140 80 NA NA NA NA NA NA 2 15 130 80 120 80 120 90 130 90 NA NA 3 20 130 85 120 80 140 80 130 80 120 80 4 24 150 85 160 85 140 95 140 85 145 90 5 33 140 80 145 85 140 80 130 85 140 80 6 37 159 77 160 80 159 75 145 80 146 79 sbp_v6 dbp_v6 1 NA NA 2 NA NA 3 NA NA 4 140 90 5 140 75 6 146 70 1.2.1 Wide to long To use the pivot_longer() function, we need to specify the dataframe we want to reshape as the first argument, and then indicate the variables we want to verticalize; this can be done by listing them comma separated, or by indicating a range of variables, as done below. In addition, we may optionally provide a name for the (new) variable that will contain the names of verticalized variables: pivot_longer(bp_wide, sbp_v1:dbp_v6, names_to = &quot;variable&quot;) %&gt;% head(15) # A tibble: 15 × 3 pid variable value &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; 1 11 sbp_v1 130 2 11 dbp_v1 80 3 11 sbp_v2 140 4 11 dbp_v2 80 5 11 sbp_v3 NA 6 11 dbp_v3 NA 7 11 sbp_v4 NA 8 11 dbp_v4 NA 9 11 sbp_v5 NA 10 11 dbp_v5 NA 11 11 sbp_v6 NA 12 11 dbp_v6 NA 13 15 sbp_v1 130 14 15 dbp_v1 80 15 15 sbp_v2 120 Because not all patients had their blood pressure measured in all six visits, many rows in the resulting dataframe are useless (e.g., sbp_v3 to dbp_v6 for patient 11). These can be ommited using function na.omit(): bp_long &lt;- pivot_longer(bp_wide, sbp_v1:dbp_v6, names_to = &quot;variable&quot;) %&gt;% na.omit() bp_long # A tibble: 3,038 × 3 pid variable value &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; 1 11 sbp_v1 130 2 11 dbp_v1 80 3 11 sbp_v2 140 4 11 dbp_v2 80 5 15 sbp_v1 130 6 15 dbp_v1 80 7 15 sbp_v2 120 8 15 dbp_v2 80 9 15 sbp_v3 120 10 15 dbp_v3 90 # … with 3,028 more rows 1.2.2 Long to wide To use the pivot_wider() function, we need to specify the dataframe we want to reshape as the first argument, and then indicate the variables we want to horizontalize; this is done by identifying the names and the vaues of the variables to be horizontalized in arguments names_from = and values_from =, respectively: pivot_wider(bp_long, names_from = variable, values_from = value) # A tibble: 392 × 13 pid sbp_v1 dbp_v1 sbp_v2 dbp_v2 sbp_v3 dbp_v3 sbp_v4 dbp_v4 sbp_v5 dbp_v5 &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 11 130 80 140 80 NA NA NA NA NA NA 2 15 130 80 120 80 120 90 130 90 NA NA 3 20 130 85 120 80 140 80 130 80 120 80 4 24 150 85 160 85 140 95 140 85 145 90 5 33 140 80 145 85 140 80 130 85 140 80 6 37 159 77 160 80 159 75 145 80 146 79 7 83 145 85 150 90 NA NA NA NA NA NA 8 91 150 100 NA NA NA NA NA NA NA NA 9 114 140 70 125 80 NA NA NA NA NA NA 10 145 140 80 150 85 NA NA NA NA NA NA # … with 382 more rows, and 2 more variables: sbp_v6 &lt;dbl&gt;, dbp_v6 &lt;dbl&gt; 1.2.3 Example Suppose we want to determine whether or not BP was controlled at each follow_up visit, defining BP control as SBP &lt; 140 and DBP &lt; 90. To work this out using bp_wide, a new “control” variable should be created for each sbp_ dbp_ pair, so that six new variables would be added to the dataframe, one for each of the six follow-up visits; Using bp_long is not an option, since SBP and DBP values for the same patient and visit are in different rows, and therefore the condition for control cannot be assessed, since it involves both SBP and DBP. A better structure for BP data would be one having one row for each patient visit, and SBP and DBP values in the same row. The following produces a dataframe with such structure, starting with dataframe ah, and chaining the following operations: select all variables containing the string “bp” (i.e., all BP variables). convert to long format, storing variable names in new variable variable. discard rows with a missing value. use function separate() to split the contents of variable into two new variables: measure (taking values sbp or dbp), and visit (taking values v1, v2, ...,v6`). convert to wide format, so that SBP and DBP values are horizontalized. bp &lt;- ah %&gt;% select(pid, contains(&quot;bp&quot;)) %&gt;% pivot_longer(sbp_v1:dbp_v6, names_to = &quot;variable&quot;) %&gt;% na.omit() %&gt;% separate(variable, into = c(&quot;measure&quot;, &quot;visit&quot;)) %&gt;% pivot_wider(names_from = measure, values_from = value) bp # A tibble: 1,519 × 4 pid visit sbp dbp &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; 1 11 v1 130 80 2 11 v2 140 80 3 15 v1 130 80 4 15 v2 120 80 5 15 v3 120 90 6 15 v4 130 90 7 20 v1 130 85 8 20 v2 120 80 9 20 v3 140 80 10 20 v4 130 80 # … with 1,509 more rows This is possibly the most sensible structure to store BP data. Now it is very easy to compute the required variable informing on BP control: bp %&gt;% mutate(bp_control = ifelse(sbp &lt; 140 &amp; dbp &lt; 90, &quot;yes&quot;, &quot;no&quot;)) # A tibble: 1,519 × 5 pid visit sbp dbp bp_control &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; 1 11 v1 130 80 yes 2 11 v2 140 80 no 3 15 v1 130 80 yes 4 15 v2 120 80 yes 5 15 v3 120 90 no 6 15 v4 130 90 no 7 20 v1 130 85 yes 8 20 v2 120 80 yes 9 20 v3 140 80 no 10 20 v4 130 80 yes # … with 1,509 more rows 1.3 Summarising rows of a dataframe The dplyr package has a summarise() function that can be used to compute summaries of columns of a dataframe. The first argument to this function is a dataframe, and further arguments are used to define the summaries we want to compute. For each summary, a name must be provided, and an appropriate function used to compute the desired summary of a column. An example of use of this function follows: summarise(ah, min_of_age = min(age), max_of_age = max(age), mean_of_age = mean(age), number_of_cases = n()) min_of_age max_of_age mean_of_age number_of_cases 1 32 99 65.59 500 Even though this may prove useful in some cases, it is usually more practical to compute summary statistics with functions such as summary() in base R, or favstats(), and tally() in package mosaic. What makes summarise() really powerful is its use in conjunction with the group_by() function, to compute summaries in groups of rows. 1.3.1 Summaries in grouped data The idea of summarising groups of rows is illustrated in figure 1.5. In this process, groups of rows having the same value in a grouping variable g are reduced to a single row containing summary values for the group. These summary values are computed by applying an appropriate function to combine or operate values of the different rows in a group. Table 1.5: Summarising grouped data grouped by g g x y 1 A 10 1 B 20 2 C 30 2 D 40 3 E 50 3 F 60 summarised by g g first_x pasted_x mean_y last_y 1 A A, B 15 20 2 C C, D 35 40 3 E E, F 55 60 For instance, consider the dataframe bp produced previously, having as many rows per patient as follow-up visits in which BP was measured (sbp and dbp). Suppose we want to compute the mean of all available BP measurements for each patient, as well as the number of such measurements. To do this, we need to: Group rows by patient (pid) with group_by(pid), Compute the required summaries with summarise(), providing a name for each, and Ungroup the dataframe with ungroup(). This is done by the following code: bp %&gt;% group_by(pid) %&gt;% # define the groups summarise(mean_sbp = mean(sbp), # computes the mean of sbp values mean_dbp = mean(dbp), # computes the mean of dbp values measurements = n()) %&gt;% # comptes the number of assessments (rows) ungroup() # A tibble: 392 × 4 pid mean_sbp mean_dbp measurements &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; 1 11 135 80 2 2 15 125 85 4 3 20 128 81 5 4 24 146. 88.3 6 5 33 139. 80.8 6 6 37 152. 76.8 6 7 83 148. 87.5 2 8 91 150 100 1 9 114 132. 75 2 10 145 145 82.5 2 # … with 382 more rows The resulting dataframe has only one row per patient (pid), and the summaries computed are the remaining variables (mean_sbp, mean_dbp, and measurements). In computing summaries of a variable, we can use any function which is appropriate for the variable type. Variables sbp and dbp in bp are numeric variables, and we used the mean() function to compute their means for each patient. Other functions for numeric variables could have been used here, such as min(), max(), or median(). Similarly, character variables can be summarised using functions that are appropriate for characters. For example, consider the following dataframe containing the adverse events experienced by three patients: ae &lt;- data.frame(pid = c(1,2,2,2,3,3), adverse_event = c(&quot;Headache&quot;, &quot;Nausea&quot;, &quot;Vomiting&quot;, &quot;Abdominal cramps&quot;, &quot;Hip fracture&quot;, &quot;Anemia&quot;)) ae pid adverse_event 1 1 Headache 2 2 Nausea 3 2 Vomiting 4 2 Abdominal cramps 5 3 Hip fracture 6 3 Anemia Suppose we want to produce a report, showing all events for each patient. The following code uses the paste()function with option collapse = to write all events, as a single character value for each patient: ae %&gt;% group_by(pid) %&gt;% summarise(adverse_events = paste(adverse_event, collapse = &quot;, &quot;)) %&gt;% ungroup() # A tibble: 3 × 2 pid adverse_events &lt;dbl&gt; &lt;chr&gt; 1 1 Headache 2 2 Nausea, Vomiting, Abdominal cramps 3 3 Hip fracture, Anemia 1.3.2 Example 1 Suppose we want to compute how many anti-hypertensive drugs is taking each patient. The following script starts with dataframe ah, then selects the patient identified (pid) and the drug treatment variables (bb to other), then reshapes to a long format, and last changes values 2 to 0. The resulting dataframe is saved as drugs_longfor later use. drugs_long &lt;- ah %&gt;% select(pid, bb:other) %&gt;% pivot_longer(bb:other, names_to = &quot;drug&quot;) %&gt;% # verticalize drugs mutate(value = ifelse(value == 2, 0, value)) # recode values: 2 -&gt; 0 drugs_long # A tibble: 3,500 × 3 pid drug value &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; 1 11 bb 1 2 11 diur 0 3 11 acei 0 4 11 arb 0 5 11 cbb 0 6 11 ab 0 7 11 other 0 8 15 bb 0 9 15 diur 0 10 15 acei 1 # … with 3,490 more rows Note that, for any patient and drug, value is 1 if the patient is taking the drug, and 0 otherwise. Therefore, for any particular patient, the sum of the value’s will be equal to the number of drugs the patient is taking. This can be computed with summarise() (using the sum() function) after grouping by patient: drugs_long %&gt;% group_by(pid) %&gt;% # define groups by pid summarise(number_of_drugs = sum(value)) %&gt;% # sumaries for each group ungroup() # undo the grouping # A tibble: 500 × 2 pid number_of_drugs &lt;dbl&gt; &lt;dbl&gt; 1 11 1 2 15 1 3 20 0 4 24 1 5 33 1 6 37 2 7 50 0 8 83 1 9 91 1 10 114 2 # … with 490 more rows In the previous example, we split the process in two steps to show the structure of the data after pivot_longer(), and the result of the mutate() statement used to recode the value 2 (corresponding to drugs not taken) to 0. However, the whole process can be done in a single step, as shown below: ah %&gt;% select(pid, bb:other) %&gt;% pivot_longer(bb:other, names_to = &quot;drug&quot;) %&gt;% # verticalize drugs mutate(value = ifelse(value == 2, 0, value)) %&gt;% # recode values: 2 -&gt; 0 group_by(pid) %&gt;% # define groups by pid summarise(number_of_drugs = sum(value)) %&gt;% # sumaries for each group ungroup() # undo the grouping # A tibble: 500 × 2 pid number_of_drugs &lt;dbl&gt; &lt;dbl&gt; 1 11 1 2 15 1 3 20 0 4 24 1 5 33 1 6 37 2 7 50 0 8 83 1 9 91 1 10 114 2 # … with 490 more rows 1.3.3 Example 2 As a second example, suppose we want to pick the last available BP measurement for each patient. Starting with the bp dataframe created previously, we can summarise measurements for sbp and dbp using the last() function, which picks the last value in each group (i.e., in the last row of each group): bp %&gt;% group_by(pid) %&gt;% summarise(last_sbp = last(sbp), # pick the last sbp for each patient last_dbp = last(dbp)) %&gt;% # pick the last dbp for each patient ungroup() # A tibble: 392 × 3 pid last_sbp last_dbp &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; 1 11 140 80 2 15 130 90 3 20 120 80 4 24 140 90 5 33 140 75 6 37 146 70 7 83 150 90 8 91 150 100 9 114 125 80 10 145 150 85 # … with 382 more rows Note that the resulting dataframe contains a single row per patient, and the variables have the names provided in the summarise() function call. 1.4 Combining dataframes It is quite common to organise all the data collected in a clinical study in several dataframes, each having a relatively small number of thematically related variables. This is preferable to having a single dataframe packed with lots of variables. Moreover, different sets of variables may require a different tidy structure. For instance, demographic variables such as region, age and sex, are observed just once per patient, and therefore can be accomodated in a dataframe having one row per patient. However, blood presure values (sbp and dbp) may be observed at several visits, thus requiring several rows per patient (one for each visit) for an optimal, tidy structure. A better way to store the data in dataframe ah would be to split it in several dataframes, as suggested in table 1.6: Table 1.6: The DISEHTAE data distributed in four dataframes dataframe variables demo pid, data_xtract_dt, region, age, sex, ah_dx_dt bp pid, visit, sbp, dbp risk_factors pid, glucose, dx_dm, total_c, hdl_c, ldl_c, trigly, dx_dyslip, smoke, weight, height, dx_lvh, cv_risk_record, creatinine treatments pid, lmr, bb, diur, acei, arb, cbb, ab, other With the study data structured this way, the need of combining data from different dataframes will arise very soon. For instance, to compare the frequency of different treatments accoding to sex, dataframes demo and treatments should be combined. Of course, rows in both dataframes should be combined by patient, and this is why the pid variable should be present in all dataframes. 1.4.1 Joins The operation of combining dataframes on (one or more) common key variables (like pid) is called a join. Package dplyr includes several functions performing diferent type of joins, but all of them have a similar syntax: the first two arguments should be the dataframes to combine, and a further argument by = indicates the key variable(s) used to match rows. The functions differ in what they return when there are non-matching rows. The following figure illustrates the use of these functions and the result they produce: Table 1.7: Joins of dataframes a and b a x y 1 A 2 B 3 C b x z 1 10 2 20 4 40 left_join(a, b, by = “x”) x y z 1 A 10 2 B 20 3 C NA right_join(a, b, by = “x”) x y z 1 A 10 2 B 20 4 NA 40 inner_join(a, b, by = “x”) x y z 1 A 10 2 B 20 full_join(a, b, by = “x”) x y z 1 A 10 2 B 20 3 C NA 4 NA 40 In words: left_join(a, b, by =\"x\") returns all rows in a and matching rows in b. right_join(a, b, by =\"x\") returns all rows in b and matching rows in a. inner_join(a, b, by =\"x\") returns all matching rows. full_join(a, b, by =\"x\") returns all rows in a and b. For example, this will combine data from demo and treatments. Because both dataframes have all 500 patients, all four types of join will produce the same result. To verify it we use the dim() function, which returns the dimension of a dataframe, that is, its number of rows and columns: left_join(demo, treatments, by = &quot;pid&quot;) %&gt;% dim() [1] 500 14 right_join(demo, treatments, by = &quot;pid&quot;) %&gt;% dim() [1] 500 14 inner_join(demo, treatments, by = &quot;pid&quot;) %&gt;% dim() [1] 500 14 full_join(demo, treatments, by = &quot;pid&quot;) %&gt;% dim() [1] 500 14 All four joins above produced a dataframe with 500 rows and 14 variables. When the key variable has a different name in the two dataframes (e.g., x1 and x2), the names should be specified as a character vector in the by = argument (e.g., by = c(\"x1\", \"x2\")). When there is more than one matching variable, these should be specified as a vector. For example, suppose we had an additional dataframe devices specifying the BP measurement device used in every visit: sphygmomanometer or automatic BP measurement (ABPM). # A tibble: 1,519 × 3 pid visit device &lt;dbl&gt; &lt;chr&gt; &lt;fct&gt; 1 11 v1 ABPM 2 11 v2 ABPM 3 15 v1 sphygmomanometer 4 15 v2 sphygmomanometer 5 15 v3 sphygmomanometer 6 15 v4 ABPM 7 20 v1 sphygmomanometer 8 20 v2 ABPM 9 20 v3 sphygmomanometer 10 20 v4 ABPM # … with 1,509 more rows If we want to compare BP values among devices, we need to merge dataframes bp and devices by patient and visit, so that in this case we have two key variables. The following script shows how to: left_join(bp, devices, by = c(&quot;pid&quot;, &quot;visit&quot;)) # A tibble: 1,519 × 5 pid visit sbp dbp device &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; 1 11 v1 130 80 ABPM 2 11 v2 140 80 ABPM 3 15 v1 130 80 sphygmomanometer 4 15 v2 120 80 sphygmomanometer 5 15 v3 120 90 sphygmomanometer 6 15 v4 130 90 ABPM 7 20 v1 130 85 sphygmomanometer 8 20 v2 120 80 ABPM 9 20 v3 140 80 sphygmomanometer 10 20 v4 130 80 ABPM # … with 1,509 more rows If the by = argument is omitted, variables having the same name in both dataframes will be used as keys for the matching. So, the following code produces the same result as before. Note the message issued informing on the key variables used to match rows. left_join(bp, devices) Joining, by = c(&quot;pid&quot;, &quot;visit&quot;) # A tibble: 1,519 × 5 pid visit sbp dbp device &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; 1 11 v1 130 80 ABPM 2 11 v2 140 80 ABPM 3 15 v1 130 80 sphygmomanometer 4 15 v2 120 80 sphygmomanometer 5 15 v3 120 90 sphygmomanometer 6 15 v4 130 90 ABPM 7 20 v1 130 85 sphygmomanometer 8 20 v2 120 80 ABPM 9 20 v3 140 80 sphygmomanometer 10 20 v4 130 80 ABPM # … with 1,509 more rows This should be used with caution to avoid undesired results that may occur if either some of the intended key variables have different names in both dataframes, or an unintended key has the same name in both dataframes. When there is more than one matching row in one of the dataframes, variables from the other dataframe will be repeated. For instance, demo has one row per patient, and bp has several rows per patient. If joined, values of variables from demo will be repeated for all matching rows in bp: left_join(demo, bp) %&gt;% head() pid data_xtract_dt region age sex ah_dx_dt visit sbp dbp 1 11 2003-03-15 6 52 1 1998-01-01 v1 130 80 2 11 2003-03-15 6 52 1 1998-01-01 v2 140 80 3 15 2003-03-15 6 57 2 1997-01-01 v1 130 80 4 15 2003-03-15 6 57 2 1997-01-01 v2 120 80 5 15 2003-03-15 6 57 2 1997-01-01 v3 120 90 6 15 2003-03-15 6 57 2 1997-01-01 v4 130 90 A right-join is just the opposite of a left-join, so that left_join(a, b, by = \"x\") will produce the same result as right_join(b, a, by = \"x\"). The left_join of demo and bp will have all patients in demo. However, not all these patients have a matching row in bp, and therefore sbp and dbp will be missing for some rows: lj &lt;- left_join(demo, bp) nrow(lj) [1] 1627 colSums(is.na(lj)) pid data_xtract_dt region age sex 0 0 0 0 27 ah_dx_dt visit sbp dbp 759 108 108 108 We see that lj has 1627 rows, but 108 missings in both sbp and dbp. An inner join of demo and bp will not include these rows, since only matching rows are retained, but now there are no missings in sbp or dbp. ij &lt;- inner_join(demo, bp) nrow(ij) [1] 1519 colSums(is.na(ij)) pid data_xtract_dt region age sex 0 0 0 0 23 ah_dx_dt visit sbp dbp 683 0 0 0 Last, a full join of demo and bp will include patients appearing in either dataframe, even if no matching row is found in the other: ij &lt;- full_join(demo, bp) nrow(ij) [1] 1627 colSums(is.na(ij)) pid data_xtract_dt region age sex 0 0 0 0 27 ah_dx_dt visit sbp dbp 759 108 108 108 1.4.2 Example 1: left- and right-joins Suppose we want to exclude from analysis those patients with unknown (missing) sex or date of diagnosis of arterial hypertension. These are the only variables having missing values in demo: colSums(is.na(demo)) pid data_xtract_dt region age sex 0 0 0 0 9 ah_dx_dt 249 To get rid of cases with incomplete data, we can use function na.omit(), save the result as demo_complete, and see how many rows are left: demo_complete &lt;- na.omit(demo) # remove rows with missing values nrow(demo_complete) # how many rows? [1] 249 The dataframe demo_complete has 249 rows. Now suppose we want to analyze treatments by sex. We need to merge demo_complete with treatments, so that only patients in the former are retained. demo_treat &lt;- left_join(demo_complete, treatments, by = &quot;pid&quot;) head(demo_treat) pid data_xtract_dt region age sex ah_dx_dt lmr bb diur acei arb cbb ab 1 11 2003-03-15 6 52 1 1998-01-01 1 1 2 2 2 2 2 2 15 2003-03-15 6 57 2 1997-01-01 1 2 2 1 2 2 2 3 20 2003-05-13 1 62 1 2003-04-10 1 2 2 2 2 2 2 4 24 2003-05-27 10 69 2 1993-01-01 1 2 1 2 2 2 2 5 33 2003-05-28 10 70 2 1994-01-01 1 2 1 2 2 2 2 6 37 2003-06-14 9 64 2 1995-04-07 1 2 1 2 1 2 2 other 1 2 2 2 3 2 4 2 5 2 6 2 We see that the result includes all variables in both dataframes, but only rows in demo_complete (249 rows): nrow(demo_treat) [1] 249 Join functions can be chained just as any other function, and therefore the following code is equivalent to the previous one: demo_complete %&gt;% left_join(treatments, by = &quot;pid&quot;) %&gt;% head() pid data_xtract_dt region age sex ah_dx_dt lmr bb diur acei arb cbb ab 1 11 2003-03-15 6 52 1 1998-01-01 1 1 2 2 2 2 2 2 15 2003-03-15 6 57 2 1997-01-01 1 2 2 1 2 2 2 3 20 2003-05-13 1 62 1 2003-04-10 1 2 2 2 2 2 2 4 24 2003-05-27 10 69 2 1993-01-01 1 2 1 2 2 2 2 5 33 2003-05-28 10 70 2 1994-01-01 1 2 1 2 2 2 2 6 37 2003-06-14 9 64 2 1995-04-07 1 2 1 2 1 2 2 other 1 2 2 2 3 2 4 2 5 2 6 2 The advantage of chaining is that we can modify the first dataframe as needed, and then do the join. For instance, to keep the result as simple as possible, we may want to select only the needed variables in demo_complete before left-joining the resulting dataframe to treatments: demo_complete %&gt;% select(pid, sex) %&gt;% # to keep only needed variables left_join(treatments, by = &quot;pid&quot;) %&gt;% # left_join with treatments head() pid sex lmr bb diur acei arb cbb ab other 1 11 1 1 1 2 2 2 2 2 2 2 15 2 1 2 2 1 2 2 2 2 3 20 1 1 2 2 2 2 2 2 2 4 24 2 1 2 1 2 2 2 2 2 5 33 2 1 2 1 2 2 2 2 2 6 37 2 1 2 1 2 1 2 2 2 1.4.3 Example 2: inner- and full-joins Suppose we want to analyse some patient summaries of BP measurements, such as the number of visits in which BP was monitored, and the mean BP values of all measurements of a patient. First we need to compute these summaries for each patient: bp_summaries &lt;- bp %&gt;% group_by(pid) %&gt;% summarise(n_of_measurements = n(), mean_sbp = mean(sbp), mean_dbp = mean(dbp)) %&gt;% ungroup() bp_summaries # A tibble: 392 × 4 pid n_of_measurements mean_sbp mean_dbp &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; 1 11 2 135 80 2 15 4 125 85 3 20 5 128 81 4 24 6 146. 88.3 5 33 6 139. 80.8 6 37 6 152. 76.8 7 83 2 148. 87.5 8 91 1 150 100 9 114 2 132. 75 10 145 2 145 82.5 # … with 382 more rows Now we should merge demo_complete and bp_summaries, but they have a different number of rows (249 and 392, respectively): some patients are present in both dataframes, but some others are present in just one of them. An inner join will keep only patients that are present in both dataframes. Because neither demo_complete nor bp_summaries have missings, the resulting dataframe is free of missings: inner &lt;- inner_join(demo_complete, bp_summaries) nrow(inner) [1] 217 colSums(is.na(inner)) pid data_xtract_dt region age 0 0 0 0 sex ah_dx_dt n_of_measurements mean_sbp 0 0 0 0 mean_dbp 0 However, a full join will include patients appearing in any dataframe, and therefore, patients not appearing in one of them will have missings in variables comming from the other: full &lt;- full_join(demo_complete, bp_summaries) nrow(full) [1] 424 colSums(is.na(full)) pid data_xtract_dt region age 0 175 175 175 sex ah_dx_dt n_of_measurements mean_sbp 175 175 32 32 mean_dbp 32 1.4.4 Binding Sometimes the data of a study is received in different batches, each batch including different patients. For instance, suppose the ah data was received in three data files containing different patients. Each of these files would be read, producing one dataframe each. To simulate this situation, the following code splits the ah dataframe in three parts, using the slice() function: batch_1 &lt;- slice(ah, 1:200) batch_2 &lt;- slice(ah, 201:400) batch_3 &lt;- slice(ah, 401:500) In such a case, the rows in each dataframe should be binded into a single dataframe. This can be done with function bind_rows(): batches_123 &lt;- bind_rows(batch_1, batch_2, batch_3) nrow(batches_123) [1] 500 The resulting dataframe batches_123 has now all 500 rows. If some of the batches contained a variable not present in the remaining dataframes, this variable would be missing in rows coming from the later. An analogous function bind_cols() exists, allowing to bind the columns of several dataframes. However, the binding is done by row position, not by value of a common key variable, which limits its usefulness. Resources Data transformation with dplyr and Data wrangling are two cheatsheets, very handy for a fast look-up of the main functions in packages dplyr and tidyr. Worried about understanding joins? See these annimations! A complete catalog of argument variations in dplyr::select(). A collection of lesser known but useful dplyrfunctions is presented here. A tidyr tutorial where you can learn about other useful functions in this package. For complex recoding of variables, this is a good explanation on how to use the case_when() function in dplyr, with examples. A comparison of dplyr funtions to their base R equivalents can be found here. If you work with really HUGE datasets you may want to know about the data.table package for more efficient dataframe operations. A comparison to of data.table and dplyr can be found here. Exercises Read the DISEHTAE data and create the four dataframes defined in table 1.6. Starting from dataframe bp, create a new dataframe bp_monitoring, with one row per patient and two variables: pid and num_bpm, the last one being the number of blood pressure measurements (i.e., the number of visits in which BP was measured). Starting from dataframe treatments, create a new dataframe num_drugs with one row per patient and two variables: pid and num_drugs, the last one being the number of drugs a patient is taking. Compute the number of cardiovascular risk factors for each patient (overweight defined as BMI of 25 kg/m^2 or more, diabtes mellitus, dyslipidemia, left venticular hypertrophy, current smoker), assuming that when a risk factor is missing, it is not present. Proceed as follows, starting from dataframe ah: select pid and relevant variables. use mutate() to create new variables overweight and current_smoker, as 1 (for yes) or 2 (for no). select pid and yes/no variables (coded as 1/2). use across() in a mutate() statement to recode all yes/no variables so that they take values 1 (for yes) or 0 (for no). reshape to long format group the dataframe by patient and compute the sum of values for each patient. ungroup the dataframe. You should end up with a dataframe num_risk_factors having only two variables: pid and num_cvrf (number of cardiovascular risk factors). What is the distribution of num_cvrf? How many patients have none, one, two, three, four, or five risk factors? Using the %&gt;% operator to chain operations, do the following: Starting with demo, combine it with num_drugs, so that only patients with complete demographic data appear in the result. Then combine the previous result with num_cvrf, so that only patients with complete demographic data appear in the result. Then combine the previous result with bp_monitoring, so that only patients with complete demographic data appear in the result. You should end up with a dataframe having the following variables: pid, age, sex, num_drugs, num_cvrf and num_bpm. The package gapminder includes a dataframe of the same name containing data on life expectancy by year and country of the world: library(gapminder) gapminder # A tibble: 1,704 × 6 country continent year lifeExp pop gdpPercap &lt;fct&gt; &lt;fct&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; 1 Afghanistan Asia 1952 28.8 8425333 779. 2 Afghanistan Asia 1957 30.3 9240934 821. 3 Afghanistan Asia 1962 32.0 10267083 853. 4 Afghanistan Asia 1967 34.0 11537966 836. 5 Afghanistan Asia 1972 36.1 13079460 740. 6 Afghanistan Asia 1977 38.4 14880372 786. 7 Afghanistan Asia 1982 39.9 12881816 978. 8 Afghanistan Asia 1987 40.8 13867957 852. 9 Afghanistan Asia 1992 41.7 16317921 649. 10 Afghanistan Asia 1997 41.8 22227415 635. # … with 1,694 more rows Using this dataframe, answer the following questions: What was the population of Europe in 2007? What was the average life expectancy for European countries in 2007? and what were minimum and maximum life expectancy values in Europe? Produce a graphic to see the evolution of the average life expectancy by continent from 1960 to 2000. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
